{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position(H, W, is_cuda=True):\n",
    "    if is_cuda:\n",
    "        loc_w = torch.linspace(-1.0, 1.0, W).cuda().unsqueeze(0).repeat(H, 1)\n",
    "        loc_h = torch.linspace(-1.0, 1.0, H).cuda().unsqueeze(1).repeat(1, W)\n",
    "    else:\n",
    "        loc_w = torch.linspace(-1.0, 1.0, W).unsqueeze(0).repeat(H, 1)\n",
    "        loc_h = torch.linspace(-1.0, 1.0, H).unsqueeze(1).repeat(1, W)\n",
    "    loc = torch.cat([loc_w.unsqueeze(0), loc_h.unsqueeze(0)], 0).unsqueeze(0)\n",
    "    return loc\n",
    "\n",
    "\n",
    "def stride(x, stride):\n",
    "    b, c, h, w = x.shape\n",
    "    return x[:, :, ::stride, ::stride]\n",
    "\n",
    "def init_rate_half(tensor):\n",
    "    if tensor is not None:\n",
    "        tensor.data.fill_(0.5)\n",
    "\n",
    "def init_rate_0(tensor):\n",
    "    if tensor is not None:\n",
    "        tensor.data.fill_(0.)\n",
    "\n",
    "\n",
    "class ACmix(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_att=7, head=4, kernel_conv=3, stride=1, dilation=1):\n",
    "        super(ACmix, self).__init__()\n",
    "        self.in_planes = in_planes\n",
    "        self.out_planes = out_planes\n",
    "        self.head = head\n",
    "        self.kernel_att = kernel_att\n",
    "        self.kernel_conv = kernel_conv\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "        self.rate1 = torch.nn.Parameter(torch.Tensor(1))\n",
    "        self.rate2 = torch.nn.Parameter(torch.Tensor(1))\n",
    "        self.head_dim = self.out_planes // self.head\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=1)\n",
    "        self.conv2 = nn.Conv2d(in_planes, out_planes, kernel_size=1)\n",
    "        self.conv3 = nn.Conv2d(in_planes, out_planes, kernel_size=1)\n",
    "        self.conv_p = nn.Conv2d(2, self.head_dim, kernel_size=1)\n",
    "\n",
    "        self.padding_att = (self.dilation * (self.kernel_att - 1) + 1) // 2\n",
    "        self.pad_att = torch.nn.ReflectionPad2d(self.padding_att)\n",
    "        self.unfold = nn.Unfold(kernel_size=self.kernel_att, padding=0, stride=self.stride)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "        self.fc = nn.Conv2d(3*self.head, self.kernel_conv * self.kernel_conv, kernel_size=1, bias=False)\n",
    "        self.dep_conv = nn.Conv2d(self.kernel_conv * self.kernel_conv * self.head_dim, out_planes, kernel_size=self.kernel_conv, bias=True, groups=self.head_dim, padding=1, stride=stride)\n",
    "\n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        init_rate_half(self.rate1)\n",
    "        init_rate_half(self.rate2)\n",
    "        kernel = torch.zeros(self.kernel_conv * self.kernel_conv, self.kernel_conv, self.kernel_conv)\n",
    "        for i in range(self.kernel_conv * self.kernel_conv):\n",
    "            kernel[i, i//self.kernel_conv, i%self.kernel_conv] = 1.\n",
    "        kernel = kernel.squeeze(0).repeat(self.out_planes, 1, 1, 1)\n",
    "        self.dep_conv.weight = nn.Parameter(data=kernel, requires_grad=True)\n",
    "        self.dep_conv.bias = init_rate_0(self.dep_conv.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        q, k, v = self.conv1(x), self.conv2(x), self.conv3(x)\n",
    "        scaling = float(self.head_dim) ** -0.5\n",
    "        b, c, h, w = q.shape\n",
    "        h_out, w_out = h//self.stride, w//self.stride\n",
    "\n",
    "\n",
    "# ### att\n",
    "        # ## positional encoding\n",
    "        pe = self.conv_p(position(h, w, x.is_cuda))\n",
    "\n",
    "        q_att = q.view(b*self.head, self.head_dim, h, w) * scaling\n",
    "        k_att = k.view(b*self.head, self.head_dim, h, w)\n",
    "        v_att = v.view(b*self.head, self.head_dim, h, w)\n",
    "\n",
    "        if self.stride > 1:\n",
    "            q_att = stride(q_att, self.stride)\n",
    "            q_pe = stride(pe, self.stride)\n",
    "        else:\n",
    "            q_pe = pe\n",
    "\n",
    "        unfold_k = self.unfold(self.pad_att(k_att)).view(b*self.head, self.head_dim, self.kernel_att*self.kernel_att, h_out, w_out) # b*head, head_dim, k_att^2, h_out, w_out\n",
    "        unfold_rpe = self.unfold(self.pad_att(pe)).view(1, self.head_dim, self.kernel_att*self.kernel_att, h_out, w_out) # 1, head_dim, k_att^2, h_out, w_out\n",
    "        \n",
    "        att = (q_att.unsqueeze(2)*(unfold_k + q_pe.unsqueeze(2) - unfold_rpe)).sum(1) # (b*head, head_dim, 1, h_out, w_out) * (b*head, head_dim, k_att^2, h_out, w_out) -> (b*head, k_att^2, h_out, w_out)\n",
    "        att = self.softmax(att)\n",
    "\n",
    "        out_att = self.unfold(self.pad_att(v_att)).view(b*self.head, self.head_dim, self.kernel_att*self.kernel_att, h_out, w_out)\n",
    "        out_att = (att.unsqueeze(1) * out_att).sum(2).view(b, self.out_planes, h_out, w_out)\n",
    "\n",
    "## conv\n",
    "        f_all = self.fc(torch.cat([q.view(b, self.head, self.head_dim, h*w), k.view(b, self.head, self.head_dim, h*w), v.view(b, self.head, self.head_dim, h*w)], 1))\n",
    "        f_conv = f_all.permute(0, 2, 1, 3).reshape(x.shape[0], -1, x.shape[-2], x.shape[-1])\n",
    "        \n",
    "        out_conv = self.dep_conv(f_conv)\n",
    "\n",
    "        return self.rate1 * out_att + self.rate2 * out_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellpose",
   "language": "python",
   "name": "cellpose"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
